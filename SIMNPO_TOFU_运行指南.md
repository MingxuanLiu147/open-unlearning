# SimNPO on TOFU æ•°æ®é›†è¿è¡ŒæŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•ä½¿ç”¨ **SimNPO ç®—æ³•**åœ¨ **TOFU æ•°æ®é›†**ä¸Šè¿è¡Œ unlearningï¼Œä½¿ç”¨ **Llama-3.2-1B-Instruct** æ¨¡å‹ï¼Œ**forget=10%** çš„é…ç½®ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨æä¾›çš„è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# ç›´æ¥è¿è¡Œ
bash run_simnpo_tofu_1b.sh
```

### æ–¹æ³• 2: ä½¿ç”¨å‘½ä»¤è¡Œï¼ˆæ›´çµæ´»ï¼‰

```bash
CUDA_VISIBLE_DEVICES=4 HYDRA_FULL_ERROR=1 python src/train.py \
    --config-name=unlearn.yaml \
    experiment=unlearn/tofu/default \
    trainer=SimNPO \
    forget_split=forget10 \
    retain_split=retain90 \
    task_name=tofu_SimNPO_forget10_v1 \
    model.model_args.attn_implementation=eager \
    trainer.args.learning_rate=5e-5 \
    trainer.args.num_train_epochs=20 \
    trainer.args.per_device_train_batch_size=2 \
    trainer.args.gradient_accumulation_steps=8 \
    trainer.args.eval_strategy=steps \
    +trainer.args.eval_steps=100 \
    trainer.args.save_strategy=steps \
    +trainer.args.save_steps=100
```

---

## ğŸ“‹ å®Œæ•´ Pipelineï¼ˆå¯¹é½è®ºæ–‡ï¼‰

### æ­¥éª¤ 1: å‡†å¤‡é¢„è®­ç»ƒæ¨¡å‹

**ä½¿ç”¨çš„æ¨¡å‹ï¼š** `open-unlearning/tofu_Llama-3.2-1B-Instruct_full`

è¿™æ˜¯åœ¨å®Œæ•´ TOFU æ•°æ®é›†ä¸Šå¾®è°ƒè¿‡çš„ LLaMA-3.2-1B æ¨¡å‹ã€‚

**å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œæ‚¨éœ€è¦å…ˆå¾®è°ƒåŸºç¡€æ¨¡å‹ï¼š**

```bash
# åœ¨å®Œæ•´ TOFU æ•°æ®é›†ä¸Šå¾®è°ƒ LLaMA-3.2-1Bï¼ˆå¯é€‰ï¼‰
CUDA_VISIBLE_DEVICES=4 python src/train.py \
    --config-name=train.yaml \
    experiment=finetune/tofu/default \
    model=Llama-3.2-1B-Instruct \
    task_name=tofu_Llama-3.2-1B-Instruct_full
```

### æ­¥éª¤ 2: è¿è¡Œ SimNPO Unlearning

```bash
# è®¾ç½® GPU
export CUDA_VISIBLE_DEVICES=4

# è¿è¡Œè®­ç»ƒ
HYDRA_FULL_ERROR=1 python src/train.py \
    --config-name=unlearn.yaml \
    experiment=unlearn/tofu/default \
    trainer=SimNPO \
    forget_split=forget10 \
    retain_split=retain90 \
    task_name=tofu_SimNPO_forget10_v1 \
    model.model_args.pretrained_model_name_or_path=open-unlearning/tofu_Llama-3.2-1B-Instruct_full \
    trainer.args.learning_rate=5e-5 \
    trainer.args.num_train_epochs=20 \
    trainer.args.per_device_train_batch_size=2 \
    trainer.args.gradient_accumulation_steps=8 \
    trainer.args.eval_strategy=steps \
    +trainer.args.eval_steps=100 \
    trainer.args.save_strategy=steps \
    +trainer.args.save_steps=100 \
    trainer.args.logging_steps=10
```

**è®­ç»ƒæ—¶é—´ä¼°è®¡ï¼š**
- å•å¡ A100/V100ï¼šçº¦ 2-3 å°æ—¶
- å•å¡ 3090/4090ï¼šçº¦ 3-5 å°æ—¶

**æ˜¾å­˜å ç”¨ï¼š**
- Llama-3.2-1B + batch_size=2ï¼šçº¦ 8-12 GB

### æ­¥éª¤ 3: è¯„ä¼° Unlearning æ•ˆæœ

```bash
CUDA_VISIBLE_DEVICES=4 python src/eval.py \
    --config-name=eval.yaml \
    experiment=eval/tofu/default \
    forget_split=forget10 \
    holdout_split=holdout10 \
    model=Llama-3.2-1B-Instruct \
    task_name=tofu_SimNPO_forget10_v1 \
    model.model_args.pretrained_model_name_or_path=saves/unlearn/tofu_SimNPO_forget10_v1 \
    paths.output_dir=saves/unlearn/tofu_SimNPO_forget10_v1/evals
```

**è¯„ä¼°æ—¶é—´ï¼š** çº¦ 10-20 åˆ†é’Ÿ

### æ­¥éª¤ 4: æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹è¯„ä¼°ç»“æœ
cat saves/unlearn/tofu_SimNPO_forget10_v1/evals/TOFU_EVAL.json

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f saves/unlearn/tofu_SimNPO_forget10_v1/trainer_log.txt
```

---

## âš™ï¸ å…³é”®å‚æ•°è¯´æ˜ï¼ˆå¯¹é½è®ºæ–‡ï¼‰

### 1. SimNPO ç®—æ³•å‚æ•°

è¿™äº›å‚æ•°æ¥è‡ª [SimNPO è®ºæ–‡](https://github.com/OPTML-Group/Unlearn-Simple/blob/main/TOFU/config/forget.yaml)ï¼š

| å‚æ•° | é»˜è®¤å€¼ | è®ºæ–‡è®¾ç½® | è¯´æ˜ |
|------|--------|----------|------|
| `gamma` | 0.125 | 0.125 | Forget æŸå¤±æƒé‡ï¼ˆè®ºæ–‡ä¸­ç§°ä¸º `npo_coeff`ï¼‰|
| `alpha` | 1.0 | 1.0 | Retain æŸå¤±æƒé‡ |
| `beta` | 4.5 | 4.5 | æ¸©åº¦å‚æ•° |
| `delta` | 0.0 | 0.0 | NLL åç§»é‡ï¼ˆè®ºæ–‡ä¸­ç§°ä¸º `gamma`ï¼‰|
| `retain_loss_type` | NLL | NLL | Retain æŸå¤±ç±»å‹ï¼ˆNLL æˆ– KLï¼‰|

**ä¿®æ”¹æ–¹å¼ï¼š**
```bash
trainer.method_args.gamma=0.125
trainer.method_args.alpha=1.0
trainer.method_args.beta=4.5
trainer.method_args.delta=0.0
```

### 2. è®­ç»ƒè¶…å‚æ•°

| å‚æ•° | æ¨èå€¼ï¼ˆ1Bï¼‰ | è®ºæ–‡è®¾ç½® | è¯´æ˜ |
|------|--------------|----------|------|
| `learning_rate` | 5e-5 | 5e-5 | å­¦ä¹ ç‡ |
| `num_train_epochs` | 20 | 10-20 | è®­ç»ƒè½®æ•° |
| `per_device_train_batch_size` | 2 | 2-4 | æ¯å¡ batch size |
| `gradient_accumulation_steps` | 8 | 4-8 | æ¢¯åº¦ç´¯ç§¯æ­¥æ•° |
| `warmup_epochs` | 1.0 | 1.0 | Warmup è½®æ•° |
| `weight_decay` | 0.01 | 0.01 | æƒé‡è¡°å‡ |

**æœ‰æ•ˆ Batch Size = per_device_batch_size Ã— gradient_accumulation_steps Ã— num_gpus**

ç¤ºä¾‹ï¼š
- å•å¡ï¼š2 Ã— 8 Ã— 1 = 16
- åŒå¡ï¼š2 Ã— 4 Ã— 2 = 16

### 3. æ•°æ®é›†é…ç½®

| å‚æ•° | forget10 è®¾ç½® | è¯´æ˜ |
|------|---------------|------|
| `forget_split` | forget10 | 10% ä½œè€…æ•°æ®ï¼ˆçº¦ 176 æ¡æ ·æœ¬ï¼‰|
| `retain_split` | retain90 | 90% ä½œè€…æ•°æ®ï¼ˆçº¦ 1584 æ¡æ ·æœ¬ï¼‰|
| `holdout_split` | holdout10 | 10% holdout æ•°æ®ï¼ˆç”¨äºè¯„ä¼°ï¼‰|
| `anchor` | forget | é”šå®šåœ¨ forget æ•°æ®é›† |

**å…¶ä»–å¯ç”¨é…ç½®ï¼š**
```bash
# 1% forget
forget_split=forget01
retain_split=retain99

# 5% forget
forget_split=forget05
retain_split=retain95
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### 1. Forget Quality (FQ) - é—å¿˜è´¨é‡

**ç›®æ ‡ï¼š** è¶Šä½è¶Šå¥½ï¼ˆè¯´æ˜æ¨¡å‹æˆåŠŸ"å¿˜è®°"äº†æ•°æ®ï¼‰

**æŒ‡æ ‡ï¼š**
- `Truth Ratio`ï¼šæ¨¡å‹è¾“å‡ºçœŸå®ç­”æ¡ˆçš„æ¯”ä¾‹
- `Probability`ï¼šæ¨¡å‹åœ¨ forget æ•°æ®ä¸Šçš„è¾“å‡ºæ¦‚ç‡
- `ROUGE-L`ï¼šforget æ•°æ®ä¸Šçš„ ROUGE åˆ†æ•°

**è®ºæ–‡åŸºå‡†ï¼ˆforget10ï¼‰ï¼š**
- Truth Ratio: < 0.05ï¼ˆåº”è¯¥æ¥è¿‘ 0ï¼‰
- Probability: < 0.1ï¼ˆåº”è¯¥æ˜æ˜¾ä¸‹é™ï¼‰

### 2. Model Utility (MU) - æ¨¡å‹æ•ˆç”¨

**ç›®æ ‡ï¼š** è¶Šé«˜è¶Šå¥½ï¼ˆè¯´æ˜æ¨¡å‹åœ¨ retain æ•°æ®ä¸Šä¿æŒæ€§èƒ½ï¼‰

**æŒ‡æ ‡ï¼š**
- `ROUGE-L on Retain Set`ï¼šretain æ•°æ®ä¸Šçš„ ROUGE åˆ†æ•°
- `Probability on Retain Set`ï¼šretain æ•°æ®ä¸Šçš„è¾“å‡ºæ¦‚ç‡

**è®ºæ–‡åŸºå‡†ï¼ˆretain90ï¼‰ï¼š**
- ROUGE-L: > 0.40ï¼ˆåº”è¯¥æ¥è¿‘åŸå§‹æ¨¡å‹ï¼‰
- Probability: > 0.50ï¼ˆåº”è¯¥ä¿æŒé«˜ï¼‰

### 3. ç»¼åˆè¯„ä¼°

**å‡è¡¡æŒ‡æ ‡ï¼š**
```
Score = (1 - FQ) Ã— MU
```

**è®ºæ–‡ä¸­ SimNPO çš„å…¸å‹è¡¨ç°ï¼ˆforget10ï¼‰ï¼š**
- FQ: ~0.05-0.10
- MU: ~0.85-0.90
- Score: ~0.80-0.85

---

## ğŸ”§ å¸¸è§é…ç½®è°ƒæ•´

### 1. æ›´å¼ºçš„é—å¿˜

```bash
# å¢å¤§ forget æŸå¤±æƒé‡
trainer.method_args.gamma=0.5

# å¢å¤§æ¸©åº¦å‚æ•°ï¼ˆæ›´é™¡å³­çš„æ¢¯åº¦ï¼‰
trainer.method_args.beta=10.0

# æ›´å¤šè®­ç»ƒè½®æ•°
trainer.args.num_train_epochs=30
```

### 2. æ›´å¥½çš„æ€§èƒ½ä¿æŒ

```bash
# å¢å¤§ retain æŸå¤±æƒé‡
trainer.method_args.alpha=2.0

# å‡å° forget æŸå¤±æƒé‡
trainer.method_args.gamma=0.05

# ä½¿ç”¨ KL æ•£åº¦ï¼ˆæ›´ç¨³å®šï¼‰
trainer.method_args.retain_loss_type=KL
```

### 3. æ˜¾å­˜ä¼˜åŒ–ï¼ˆå¦‚æœæ˜¾å­˜ä¸è¶³ï¼‰

```bash
# å‡å° batch size
trainer.args.per_device_train_batch_size=1

# å¢åŠ æ¢¯åº¦ç´¯ç§¯
trainer.args.gradient_accumulation_steps=16

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
trainer.args.gradient_checkpointing=true

# ä½¿ç”¨ DeepSpeedï¼ˆæ¨èï¼‰
accelerate launch \
    --config_file configs/accelerate/zero_stage3_offload_config.json \
    src/train.py ...
```

### 4. å¤š GPU è®­ç»ƒ

```bash
# ä½¿ç”¨ accelerateï¼ˆæ¨èï¼‰
CUDA_VISIBLE_DEVICES=0,1,2,3 accelerate launch \
    --config_file configs/accelerate/default_config.yaml \
    src/train.py \
    --config-name=unlearn.yaml \
    experiment=unlearn/tofu/default \
    trainer=SimNPO \
    ...
```

---

## ğŸ“ˆ ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”

### è¿è¡Œå¤šä¸ªæ–¹æ³•è¿›è¡Œå¯¹æ¯”

```bash
#!/bin/bash

methods=("SimNPO" "GradAscent" "GradDiff" "NPO")

for method in "${methods[@]}"; do
    echo "Running ${method}..."
    
    CUDA_VISIBLE_DEVICES=4 python src/train.py \
        --config-name=unlearn.yaml \
        experiment=unlearn/tofu/default \
        trainer=${method} \
        forget_split=forget10 \
        retain_split=retain90 \
        task_name=tofu_${method}_forget10 \
        trainer.args.learning_rate=5e-5 \
        trainer.args.num_train_epochs=20
    
    # è¯„ä¼°
    CUDA_VISIBLE_DEVICES=4 python src/eval.py \
        --config-name=eval.yaml \
        experiment=eval/tofu/default \
        forget_split=forget10 \
        task_name=tofu_${method}_forget10 \
        model.model_args.pretrained_model_name_or_path=saves/unlearn/tofu_${method}_forget10
done
```

### é¢„æœŸæ€§èƒ½å¯¹æ¯”ï¼ˆforget10ï¼Œè®ºæ–‡æ•°æ®ï¼‰

| æ–¹æ³• | Forget Quality (FQ) | Model Utility (MU) | ç»¼åˆå¾—åˆ† |
|------|---------------------|-------------------|----------|
| **SimNPO** | **0.08** | **0.87** | **0.80** |
| GradAscent | 0.15 | 0.82 | 0.70 |
| GradDiff | 0.12 | 0.84 | 0.74 |
| NPO | 0.10 | 0.85 | 0.77 |

> **ç»“è®ºï¼š** SimNPO åœ¨é—å¿˜è´¨é‡å’Œæ€§èƒ½ä¿æŒä¹‹é—´è¾¾åˆ°æœ€ä½³å¹³è¡¡ã€‚

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: æ¨¡å‹æ— æ³•åŠ è½½

**é”™è¯¯ä¿¡æ¯ï¼š**
```
OSError: open-unlearning/tofu_Llama-3.2-1B-Instruct_full does not appear to be a model identifier
```

**è§£å†³æ–¹æ¡ˆï¼š**
1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨äº HuggingFace Hub
2. æˆ–ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š
   ```bash
   model.model_args.pretrained_model_name_or_path=/path/to/your/model
   ```

### Q2: æ˜¾å­˜ä¸è¶³ (OOM)

**é”™è¯¯ä¿¡æ¯ï¼š**
```
CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ–¹æ¡ˆ 1: å‡å° batch size
trainer.args.per_device_train_batch_size=1
trainer.args.gradient_accumulation_steps=16

# æ–¹æ¡ˆ 2: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
trainer.args.gradient_checkpointing=true

# æ–¹æ¡ˆ 3: ä½¿ç”¨ DeepSpeed ZeRO-3
accelerate launch \
    --config_file configs/accelerate/zero_stage3_offload_config.json \
    src/train.py ...
```

### Q3: è®­ç»ƒæŸå¤±ä¸ä¸‹é™

**å¯èƒ½åŸå› ï¼š**
- å­¦ä¹ ç‡å¤ªå°
- gamma/alpha æƒé‡è®¾ç½®ä¸å½“
- æ•°æ®é›†é—®é¢˜

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# å¢å¤§å­¦ä¹ ç‡
trainer.args.learning_rate=1e-4

# è°ƒæ•´æƒé‡
trainer.method_args.gamma=0.25
trainer.method_args.alpha=1.0

# æ£€æŸ¥æ•°æ®åŠ è½½
+trainer.args.logging_steps=1
```

### Q4: è¯„ä¼°æ—¶å‡ºé”™

**é”™è¯¯ä¿¡æ¯ï¼š**
```
KeyError: 'retain_logs_path'
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ç¡®ä¿æä¾›å‚è€ƒæ¨¡å‹çš„è¯„ä¼°æ—¥å¿—
retain_logs_path=saves/eval/tofu_Llama-3.2-1B-Instruct_retain90/TOFU_EVAL.json

# å¦‚æœä¸å­˜åœ¨ï¼Œå…ˆç”Ÿæˆå‚è€ƒè¯„ä¼°
python src/eval.py \
    experiment=eval/tofu/default \
    model.model_args.pretrained_model_name_or_path=open-unlearning/tofu_Llama-3.2-1B-Instruct_full \
    paths.output_dir=saves/eval/tofu_Llama-3.2-1B-Instruct_retain90
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡å’Œä»£ç 

1. **SimNPO è®ºæ–‡ï¼š** [Unlearn-Simple](https://github.com/OPTML-Group/Unlearn-Simple)
2. **TOFU æ•°æ®é›†ï¼š** [TOFU: A Task of Fictitious Unlearning](https://arxiv.org/abs/2401.06121)
3. **æœ¬é¡¹ç›®æ–‡æ¡£ï¼š**
   - `UNLEARNING_GUIDE_CN.md` - å®Œæ•´çš„ unlearning æŒ‡å—
   - `ä»£ç æ³¨é‡Šæ€»ç»“.md` - ä»£ç æ³¨é‡Šæ€»ç»“

### HuggingFace èµ„æº

- **æ¨¡å‹ï¼š** [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)
- **æ•°æ®é›†ï¼š** [locuslab/TOFU](https://huggingface.co/datasets/locuslab/TOFU)

---

## âœ… æ£€æŸ¥æ¸…å•

è¿è¡Œå‰ç¡®è®¤ï¼š

- [ ] GPU å¯ç”¨ä¸”æ˜¾å­˜å……è¶³ï¼ˆè‡³å°‘ 12GBï¼‰
- [ ] é¢„è®­ç»ƒæ¨¡å‹å·²å‡†å¤‡å¥½
- [ ] æ•°æ®é›†å¯è®¿é—®ï¼ˆHuggingFace æˆ–æœ¬åœ°ï¼‰
- [ ] é…ç½®æ–‡ä»¶å­˜åœ¨ï¼ˆ`configs/` ç›®å½•ï¼‰
- [ ] Python ç¯å¢ƒå·²å®‰è£…æ‰€æœ‰ä¾èµ–

è¿è¡Œåæ£€æŸ¥ï¼š

- [ ] è®­ç»ƒæŸå¤±æ­£å¸¸ä¸‹é™
- [ ] è¯„ä¼°æŒ‡æ ‡ç¬¦åˆé¢„æœŸï¼ˆFQ ä½ï¼ŒMU é«˜ï¼‰
- [ ] æ¨¡å‹å·²ä¿å­˜åˆ° `saves/unlearn/` ç›®å½•
- [ ] è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° `saves/unlearn/*/evals/` ç›®å½•

---

**æœ€åæ›´æ–°ï¼š** 2026-02-02  
**ç‰ˆæœ¬ï¼š** v1.0  
**ç»´æŠ¤è€…ï¼š** Open-Unlearning Team
