## 背景

OpenUnlearning 已提供基于 Hydra 与注册表的遗忘基准架构（train.py/eval.py，以及 model/trainer/data/evals 注册表）。目标是以最小改动将其扩展为 Know-Surgery：保留现有 CLI/配置流程，增加一层轻量 Python 流水线封装，并规划分阶段扩展（编辑、注入/PEFT、多模态、GUI）。v1 聚焦于在 8×3090 上使用 Llama-3.2-1B Instruct 与 Qwen3-1.7B Base 稳定运行 TOFU。GUI 与 UltraRAG 式一键编排为必需能力，但有意推迟到 v2 末期实现。

## 目标 / 非目标

**目标：**
- 保留现有注册表与 Hydra 组合模式；新能力以可加性模块形式加入。
- 提供最小化 Python 流水线封装，编排「数据 → 遗忘 → 评估」而不改动核心训练/评估路径。
- 统一评估产物（清单/指标/轨迹），并允许在缺失 retain 日志时优雅降级。
- 为后续知识编辑、注入（LoRA/DoRA/REFT）及多模态支持划定可扩展边界。
- 明确 GUI 需求并与 CLI 配置对齐（同一 schema，支持导入/导出兼容），实现从 v2 末期开始。

**非目标：**
- 替换或重构现有 OpenUnlearning 训练/评估入口。
- 在 v1 中自动下载数据集（数据由人工准备）。
- 在 v1 中实现 GUI、编辑、注入或多模态功能。

## 决策

- **以 Hydra 作为配置的唯一真实来源。**
  - 理由：仓库已是 Hydra 驱动且可扩展，封装层可生成/消费配置而不改变核心逻辑。
  - 备选：新建配置 schema 或替换 Hydra（因改动过大而否决）。

- **引入最小化 Python 流水线封装（而非新训练框架）。**
  - 理由：在保持改动最小、向后兼容的前提下提供一键流程。
  - 备选：仅用 Bash 脚本（不利于后续 GUI 扩展）、全新流水线引擎（对 v1 过重）。

- **v1 采用模型优先、固定小模型范围（Llama-3.2-1B Instruct、Qwen3-1.7B Base）。**
  - 理由：保证在 8×3090 上稳定运行，并以最少资源假设实现可复现性。
  - 备选：大模型或 API 模型（因硬件与扩展性限制在 v1 中否决）。

- **通过能力注册表元数据做兼容性检查。**
  - 理由：在不重构注册表的前提下支持安全插件增长与 GUI 校验。
  - 备选：硬编码兼容规则（不可扩展）。

- **GUI 推迟到 v2 末期；v1 以 CLI 为主。**
  - 理由：v1 需先稳定遗忘流程；GUI 依赖配置 schema 成熟。
  - 备选：提前做 GUI（会在流水线稳定过程中面临返工风险）。

## 风险 / 权衡

- **风险：** 依赖 retain 日志的指标可能阻塞评估。
  → **缓解：** 提供优雅降级，并对缺失指标做显式标记。
- **风险：** 增加流水线封装可能重复逻辑。
  → **缓解：** 封装层仅编排现有 train/eval 入口，不重复业务逻辑。
- **风险：** 未来 GUI 需求可能推动配置变更。
  → **缓解：** 尽早定义稳定配置 schema，并用导入/导出兼容性测试保障。
- **风险：** 扩展到编辑/注入/多模态可能需要新的数据抽象。
  → **缓解：** 在 data/model 注册表元数据中预留 schema 钩子，并规划分阶段规格。

## 迁移计划

- v1 无破坏性变更。现有训练与评估脚本保持不动。
- 新配置与封装层为增量添加。用户可继续使用当前 CLI 命令。
- GUI 后续作为可选层引入，消费同一套配置。

## 待决问题

- 能力元数据应如何存储（与 config 并列的 YAML vs. Python 注册表注解）？
- 为同时支持 CLI 与未来 GUI 视图，评估产物的最小 schema 应是什么？
- 除 TOFU 外，应优先扩展哪个基准（MUSE vs. WMDP）？
- 流水线封装应在 v1 支持批量实验队列，还是推迟到 v2？
